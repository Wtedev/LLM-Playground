{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3cb737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jack Gisburn rather a cheap genius--though a good fellow enough--so\n",
      "the data length is: 20479\n"
     ]
    }
   ],
   "source": [
    "# Load the text data\n",
    "with open(\"the-verdict.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# show data statistics\n",
    "print(raw_text[20:88])\n",
    "print(\"the data length is:\", len(raw_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff2a611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'User,', ' ', \"I'm--\", ' ', 'a', ' ', 'text.']\n"
     ]
    }
   ],
   "source": [
    "# split the text based on white  spaces\n",
    "import re\n",
    "\n",
    "text = \"Hello, User, I'm-- a text.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c55b2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'User', ',', '', ' ', \"I'm\", '--', '', ' ', 'a', ' ', 'text', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([.,!?;:()]|--|\\s)', text)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f932046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'User', ',', \"I'm\", '--', 'a', 'text', '.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bdff4c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# apply tokenization to the entire raw text\u001b[39;00m\n\u001b[32m      3\u001b[39m preprocessed_text = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([.,;:?!_\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m()])|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m ,raw_text)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m preprocessed_text = [item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed_text \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m()]\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(preprocessed_text[:\u001b[32m50\u001b[39m])\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mlen\u001b[39m(preprocessed_text))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# apply tokenization to the entire raw text\n",
    "\n",
    "preprocessed_text = re.split(r'([.,;:?!_\\'()])|--|\\s' ,raw_text)\n",
    "preprocessed_text = [item.strip() for item in preprocessed_text if item.strip()]\n",
    "\n",
    "print(preprocessed_text[:50])\n",
    "print (len(preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b2a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 4399\n",
      "number of unique tokens: 1192\n"
     ]
    }
   ],
   "source": [
    "# sort the words and get the vocabulary size\n",
    "\n",
    "sorted_words = sorted(set(preprocessed_text))\n",
    "vocab_size = len(sorted_words)\n",
    "\n",
    "print (\"number of tokens: \" + str(len(preprocessed_text)))\n",
    "print (\"number of unique tokens: \" + str(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign unique integer IDs to each token\n",
    "vocab = {token:integer for integer, token in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d79e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "('\"Ah', 2)\n",
      "('\"Be', 3)\n",
      "('\"Begin', 4)\n",
      "('\"By', 5)\n",
      "('\"Come', 6)\n",
      "('\"Destroyed', 7)\n",
      "('\"Don\\'t', 8)\n",
      "('\"Gisburns\"', 9)\n",
      "('\"Grindles', 10)\n",
      "('\"Hang', 11)\n",
      "('\"Has', 12)\n",
      "('\"How', 13)\n",
      "('\"I', 14)\n",
      "('\"I\\'d', 15)\n",
      "('\"If', 16)\n",
      "('\"It', 17)\n",
      "('\"It\\'s', 18)\n",
      "('\"Jack', 19)\n",
      "('\"Money\\'s', 20)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    if i <= 20:\n",
    "        print(item)\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
